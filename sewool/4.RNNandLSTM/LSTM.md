# LSTM

- RNN은 입력 시퀀스의 시점이 길어질수록 앞쪽의 데이터가 뒤쪽으로 잘 전달되지 않아 학습 능력이 떨어진다.
- RNN을 다층 구조로 쌓으면 입력과 출력 데이터 사이의 연관 관계가 줄어들어 장기 의존성 문제가 생긴다.
- 이런 문제를 보완하는 것이 LSTM
- LSTM은 4개의 구조로 되어 있다
1. 입력 게이트는 현재 정보를 얼마나 기억할지 결정하는 게이트
2. 삭제 게이트는 이전 시점의 셀 상태값을 삭제하기 위해 사용 - 기억된 정보를 얼마나 삭제할지 강도를 결정
3. 셀 상태는 입력 게이트와 삭제 게이트의 결괏 값으로 현재 시점의 셀 상태를 계산
4. 출력 게이트는 현 시점 t의 x값과 이전 시점 t-1의 은닉 상태가 시그모이드 함수를 지난 값. 해당 값은 현 시점 t의 은닉 상태를 결정하는 일에 쓰이게 됨

은닉 상태는 단기 상태로 불리기도 하며, 장기 상태의 값이 하이퍼볼릭탄젠트 함수를 지나 -1~1의 값을 가진다.

# 양방향 LSTM

- RNN이나 LSTM은 이전 시점의 정보만을 활용 할 수 밖에 없는 단점
- 기존 LSTM에 역방향 LSTM을 추가

# 개체명 인식

- 개체명 인식이란 문장 내에 포함된 어떤 단어가 인물, 장소, 날짜 등을 의미하는 단어인지 인식하는 것
